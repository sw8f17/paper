\chapter{Acceptance Test}\label{cha:acctest}
This chapter aims to test our app using the same methodology applied to AmpMe and SoundSeeder in \myref[name]{sec:sota_test}, where we tested the offset, consistency, and drift.
Testing our app in the same way, enables us to qualitative compare \textit{Scotty} to AmpMe and SoundSeeder.
Moreover, we test to see if we fulfill the requirements presented in \myref[name]{cha:requirement_elicitation} particularly the requirements \ref{req:sync}, \ref{req:auto_off}, \ref{req:change_off}, \ref{req:pauseplay}, and \ref{req:drift}.
Furthermore, we want to see if we surpassed the milestone \ref{milestone:advanced_sync} we made in \vref{sec:milestones}.

AmpMe and SoundSeeder both have manual sliders to adjust the synchronization on each device, however we do not have this as we rely on synchronizing automatically;
therefore we will only compare our app to the synchronizations AmpMe and SoundSeeder do initially.

In total, we will test the following questions from \vref{sec:sota_test} about our app:
\begin{enumberate}
\item Is the audio synchronized without any manual adjustment?\label{itm:is_sync?}
\item Is the delay consistent between playbacks?\label{itm:is_consistent?}
\item Is the synchronization stable over time?\label{itm:is_stable?}
\end{enumberate}

\section{Results}
\vref{fig:smus_pause_resume} shows the results of the next song test for our app.
Here each data point is an average of five measurements.
\vref{fig:smus_drift_test} shows the results of the drift test for our app.

\subimport{figures/}{smus_pauseplay.tex}
\subimport{figures/}{smus_drift.tex}

\section{Discussion}
\begin{description}
    \item[\ref{itm:is_sync?} Is the audio synchronized without any manual adjustment?] \hfill \\
        This question should be considered in relation to the requirement \vref{req:auto_off}, which states that the offset should be lower than $40 ms$ between the devices.
        During our tests, as shown in \vref{fig:smus_drift_test} the offset is generally much lower than that.
        The figure \vref{fig:smus_drift_test_nofilter} contains all the data points, there are six data points which are clear outliers.
        The outliers in the results are likely due to glitches in our time synchronization.
        Preventing the glitches will be part of our future work in \vref{cha:future_work}.
        In order to better shown the general synchronization over time, we have \vref{fig:smus_drift_test_filtered}, where we show the points in the $[50;-30] ms$ range.
        If we do a linear regression on the filtered data (removing the six outliers), then the formula is: $f(x) = 0.0017x + 7.1149$, however the $R^2$ value is low at $0.0013$.
        This is caused by the fact that we often resynchronize between devices.
        Each time synchronization is completely independent, and we expect each of them to be close to correct, however we do not expect two time synchronizations in a row to be close.
        We imagine that it is possible to decrease the span of the offset by utilizing some or all of the techniques from \ac{NTP}, however we will explain this more in \vref{cha:future_work}.

        In total, the audio synchronization in \textit{Scotty} is close to $7 ms$ on average, and non of the regular data is more than $40 ms$ out of synchronization.
        This is well within the requirement we had which was $40 ms$ in as stated in requirement \ref{req:auto_off}.

    \item[\ref{itm:is_consistent?} Is the delay consistent between playbacks?] \hfill \\
        To test this we paused the playback, and resumed it, in our app this causes all devices to discard the buffer they previously had and rebuffer the audio data.
        However, since the time synchronization in our app is independent of the playback, we did not expect that the offset would change any more than it would during playback.
        In \vref{fig:smus_drift_test} we show the results of the drift test.

    \item[\ref{itm:is_stable?} Is the synchronization stable over time?] \hfill \\
        As discussed earlier, our synchronization is close to perfect on average, but jumps around more than both AmpMe and SoundSeeder.
        Since we resynchronize often, we expect our synchronization to be stable, as was observed in the test.
\end{description}
